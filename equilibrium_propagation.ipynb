{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "equilibrium-propagation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/act65/dynamics-waves-myelin/blob/master/equilibrium_propagation.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "RZBN6Q9V3CV4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G9KziU-F3MMC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def energy_fn(x, W, b):\n",
        "  \"\"\"\n",
        "  Somehow related to Hopfield nets?\n",
        "  Define what we mean by 'energy'\n",
        "  \n",
        "  - neighbor energy\n",
        "  i get the part that measures something like the label propagation.\n",
        "  distance between two strongly connected nodes should be small\n",
        "  \n",
        "  What alternatives are there? Want to explore these!\n",
        "  \n",
        "  \"\"\"\n",
        "  h = tf.nn.relu(x)\n",
        "  \n",
        "  node_energy = 0.5*tf.reduce_sum(x**2, axis=1) \n",
        "  neighbor_energy = 0.5*tf.reduce_sum(tf.expand_dims(W, 0) * (tf.expand_dims(h, 1) * tf.expand_dims(h, 2)), axis=[1,2])\n",
        "  energy = tf.reduce_sum(h*b, axis=1)\n",
        "  \n",
        "#   elastic_energy = 0.5**tf.reduce_sum(tf.expand_dims(W, 0) * (tf.expand_dims(h, 1) - tf.expand_dims(h, 2))**2, axis=[1,2])\n",
        "  return tf.reduce_mean(\n",
        "      node_energy + \n",
        "      neighbor_energy + \n",
        "      energy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "julrjuk47g5r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_sym_adj(n_nodes):\n",
        "  \"\"\"\n",
        "  Why does the adjacency matrix need to be symmetric?\n",
        "  Else we can prove that the back prop is equivalent?\n",
        "  \"\"\"\n",
        "  mat = tf.random_normal(shape=[n_nodes, n_nodes], dtype=tf.float32)\n",
        "  sym = (mat + tf.transpose(mat))/2\n",
        "  adj = sym - tf.eye(n_nodes)*sym\n",
        "  return adj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VtCCmkbz7hhy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Network():\n",
        "  \"\"\"\n",
        "  https://github.com/bscellier/Towards-a-Biologically-Plausible-Backprop\n",
        "  Rather than having two phases, want the nodes to have some temporal state.\n",
        "  If some input values were recently 'clamped' then they should \n",
        "  correlate with output values that are 'clamped' not long afterward.\n",
        "\n",
        "  So there exists a delay between the clamping of the inputs and the outputs.\n",
        "  What happens if;\n",
        "  - delay is large\n",
        "  - delay is variable\n",
        "  - ?\n",
        "\n",
        "  Might not even need to do anything smart? Bc SGD will want to find the shortest path from\n",
        "  old state (clamped at inputs), to new state (clamped at labels).\n",
        "  Optimise the parameters the minimize the distance travelled by the state!?\n",
        "  \n",
        "  What about spiking nets!?\n",
        "  \n",
        "  Pros:\n",
        "  - Can easily add more nodes or new inputs\n",
        "  \n",
        "  Cons:\n",
        "  - must simulate for n steps rather than 1 shot prediction\n",
        "  - \n",
        "  \"\"\"\n",
        "  def __init__(self, n_inputs, n_hidden, n_outputs, name=''):\n",
        "    self.n_nodes = n_inputs + n_hidden + n_outputs\n",
        "    self.beta = 10.0\n",
        "    \n",
        "    self.input_idx = tf.range(n_inputs)\n",
        "    self.output_idx = tf.range(n_inputs+n_hidden, self.n_nodes)\n",
        "        \n",
        "    with tf.variable_scope('network'):\n",
        "      self.weights = tf.Variable(get_sym_adj(self.n_nodes), name='weights')\n",
        "      self.biases = tf.Variable(tf.random_normal(shape=[1, self.n_nodes], dtype=tf.float32), name='biases')\n",
        "    self.variables = [self.weights, self.biases]\n",
        "      \n",
        "    self.opt = tf.train.AdamOptimizer(0.0001)\n",
        "    \n",
        "  def energy_loss(self, state):\n",
        "    \"\"\"\n",
        "    WANT a single loss to optimise!!\n",
        "    \"\"\"\n",
        "    with tf.name_scope('energy_loss'):\n",
        "      return tf.reduce_mean(energy_fn(state, self.weights, self.biases))\n",
        "  \n",
        "  def forcing_loss(self, state, vals, idx):\n",
        "    \"\"\"\n",
        "    How can I get grads w.r.t the parameters!?\n",
        "    dLdparam = mse(state, target)\n",
        "    \"\"\"\n",
        "    with tf.name_scope('forcing_loss'):\n",
        "      return self.beta*tf.losses.mean_squared_error(tf.gather(state, idx, axis=1), vals)\n",
        "  \n",
        "  def step(self, state):\n",
        "    with tf.name_scope('step'):\n",
        "      # Always trying to find a state with lower enegy\n",
        "      loss = self.energy_loss(state)\n",
        "      \n",
        "      if vals is not None and idx is not None:\n",
        "        loss += self.forcing_loss(state, vals, idx)\n",
        "        \n",
        "      grad = tf.gradients(loss, state)[0]\n",
        "      \n",
        "      # TODO want smarter optimisation here. AMSGrad!?\n",
        "      return state - 0.1*grad\n",
        "  \n",
        "  def forward(self, state, vals, idx, n_steps=10):\n",
        "    \"\"\"\n",
        "    Use while loop to take advantage of smart compilation!?\n",
        "    but the problem is we now have a finite window of data we can view.\n",
        "    \"\"\"\n",
        "    def step(i, state):\n",
        "      # a wrapper for self.step(...)\n",
        "      return i + 1, self.step(state, vals, idx)\n",
        "    \n",
        "    with tf.name_scope('forward'):\n",
        "      while_condition = lambda i, m : tf.less(i, n_steps)   # TODO change to state - old_state!? or low loss\n",
        "      i = tf.constant(0)\n",
        "      i_, new_state = tf.while_loop(while_condition, step, loop_vars=[i, state])\n",
        "    \n",
        "      return new_state\n",
        "  \n",
        "  def train_step(self, inputs, targets, init_state=None):\n",
        "    if init_state is None:\n",
        "      init_state = tf.zeros([tf.shape(inputs)[0], self.n_nodes])\n",
        "    \n",
        "    # clamp inputs\n",
        "    state_f = self.forward(init_state, inputs, self.input_idx)\n",
        "    self.pred = tf.gather(state_0, self.output_idx, axis=1)\n",
        "    \n",
        "    # clamp outputs\n",
        "    state_b = self.forward(targets, self.output_idx)\n",
        "    \n",
        "    # minimise the distance to be travelled/the changes to be made. lazy.\n",
        "    self.loss = tf.losses.mean_squared_error(state_f, state_b)\n",
        "    return self.opt.minimize(self.loss, var_list=self.variables, global_step=tf.train.get_or_create_global_step())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drE9Ctz2fp9s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_fn(features, labels, mode, params, config):\n",
        "    x = features['x']\n",
        "    net = Network(28*28, 64, 10)\n",
        "    train_op = net.train_step(x, labels)\n",
        "\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      loss=net.loss,\n",
        "      train_op=train_op,\n",
        "      eval_metric_ops={\"accuracy\": tf.metrics.accuracy(labels, tf.argmax(net.pred, axis=1))}\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lkr_Ml02gFC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "ae7b0164-65d7-4101-e90f-6e71fed8b74b"
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
        "train_data = mnist.train.images  # Returns np.array\n",
        "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
        "eval_data = mnist.test.images  # Returns np.array\n",
        "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
        "\n",
        "batch_size=50\n",
        "\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "      x={\"x\": train_data},\n",
        "      y=train_labels,\n",
        "      batch_size=batch_size,\n",
        "      num_epochs=1,\n",
        "      shuffle=True)\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": eval_data},\n",
        "    y=eval_labels,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn,\n",
        "  params=dict(),\n",
        "  config=tf.estimator.RunConfig(\n",
        "      model_dir='log/1',\n",
        "      save_checkpoints_steps=100,\n",
        "  ),\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-d78820c8242f>:1: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'log/0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f54143faeb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "36GAAW7rgE-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "53e0a8b5-a5f4-4921-e743-2e68e57cf77e"
      },
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    estimator.train(train_input_fn, steps=100)\n",
        "    eval_results = estimator.evaluate(eval_input_fn)\n",
        "    print(\"Evaluation_results:\\n\\t%s\\n\" % eval_results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into log/0/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3025854, step = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x23dRmN6bAsG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TODO. vector map of a 2d example!?"
      ]
    },
    {
      "metadata": {
        "id": "uvC9hVVciYBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "ee103318-7df5-43f3-f21e-d4850c358444"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-09-04 07:47:57--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.207.5.158, 52.5.182.176, 52.207.39.76, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.207.5.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  20.7MB/s    in 0.2s    \n",
            "\n",
            "2018-09-04 07:47:57 (20.7 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aCZ6aoG0jBdN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = 'EP'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pUzfemz_jHid",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-aiKRmiWjLg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0409b7ab-b06c-4e31-ae47-f9477732ed7d"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://5b92938b.ngrok.io\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3kvngTKVjYFJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}